# Appliances Energy Prediction

A machine learning system for predicting household appliance energy consumption 2 hours ahead using time-series forecasting and XGBoost quantile regression.

![App Screenshot](docs/app_screenshot.png)

## ğŸ“‹ Description

This project develops an intelligent forecasting system that predicts household appliance energy consumption using historical usage patterns and temporal features. Built on 4.5 months of granular energy data collected at 10-minute intervals from a residential building in Belgium, the system achieves:

- **26.86 Wh MAE** on test data (27.5% of mean consumption)
- **90% accuracy** within Â±50 Wh tolerance
- **58% accuracy** within Â±10 Wh for typical usage patterns
- Real-time predictions suitable for smart grid integration and energy management

The model leverages 55 engineered features including exponential moving averages, rolling statistics, lag features, and usage regime classification to capture complex temporal patterns while remaining computationally efficient for production deployment.

## ğŸ› ï¸ Tech Stack

- **Python 3.8+**
- **XGBoost** - Gradient boosting with quantile regression
- **Pandas & NumPy** - Data manipulation and numerical operations
- **Scikit-learn** - Model evaluation metrics
- **Gradio** - Interactive web interface
- **Matplotlib/Seaborn** - Visualization (notebooks)

## ğŸ“¦ Installation

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/energy-forecasting.git
cd energy-forecasting
```

2. **Create virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Download data (if not included)**

```bash
# Place your dataset in data/raw/
# Expected format: KAG_energydata_complete.csv with 'date' and 'Appliances' columns
```

## âš™ï¸ Configuration

Update `config.py` with your settings:

```python
# config.py
DATA_PATH = "data/raw/KAG_energydata_complete.csv"
MODEL_PATH = "models/xgboost_model.json"
HORIZON_HOURS = 2
TRAIN_SPLIT = 0.7
VAL_SPLIT = 0.85
RANDOM_SEED = 42
```

## ğŸš€ Usage

### Training the Model

```bash
python src/model_training.py
```

### Running the Gradio App

```bash
python app.py
```

Then navigate to `http://localhost:7860` in your browser.

### Using Notebooks

```bash
jupyter notebook
# Open notebooks in notebooks/ directory
```

## ğŸ“ Folder Structure

```
energy-forecasting/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.py                          # Configuration settings
â”œâ”€â”€ app.py                             # Gradio web application
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ KAG_energydata_complete.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ engineered_features.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb      # EDA and statistical analysis
â”‚   â”œâ”€â”€ 02_spike_analysis_eda.ipynb    # Spike behavior analysis
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb   # Feature creation process
â”‚   â”œâ”€â”€ 04_model_training.ipynb        # Model development
â”‚   â””â”€â”€ 05_evaluation.ipynb            # Performance evaluation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ feature_engineering.py         # Feature creation functions
â”‚   â”œâ”€â”€ model_training.py              # XGBoost training pipeline
â”‚   â””â”€â”€ evaluation.py                  # Metrics and analysis
â”œâ”€â”€ models/
â”‚   â””â”€â”€ xgboost_model.json             # Trained model (generated)
â””â”€â”€ docs/
    â”œâ”€â”€ app_screenshot.png
    â”œâ”€â”€ interpretability_insights.pdf
    â”œâ”€â”€ scalability_production.pdf
    â””â”€â”€ architecture.md
```

## ğŸ¯ Key Features

- **55 Engineered Features**: Temporal patterns, rolling statistics, lag features, usage regimes
- **No Data Leakage**: Proper temporal split with train-time computed historical averages
- **Quantile Regression**: Robust to outliers and skewed distributions
- **Fast Inference**: <5ms per prediction, suitable for real-time applications
- **Interpretable**: Feature importance analysis reveals exponential moving averages and recent lags dominate predictions

## ğŸ“Š Model Performance

| Metric | Value |
|--------|-------|
| MAE | 26.86 Wh |
| RMSE | 72.23 Wh |
| RÂ² Score | 0.3684 |
| MAPE | 18.54% |
| Median Error | 8.12 Wh |

### Performance by Usage Level:

- **Low usage (0-100 Wh)**: 9.01 Wh MAE - covers 73% of cases
- **Medium usage (100-200 Wh)**: 25.02 Wh MAE
- **High usage (200-300 Wh)**: 76.24 Wh MAE
- **Very high usage (>300 Wh)**: 275.03 Wh MAE



## ğŸ‘¤ Author

**Lekshmi J**
